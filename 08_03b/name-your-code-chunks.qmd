---
title: "Name your code chunks"
format: html
echo: false
---

# Data Processing

```{python}
# | label: get-penguins-data
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from palmerpenguins import load_penguins
import pandas as pd
import numpy as np

penguins_df = load_penguins()
penguins_cleaned_df = penguins_df.dropna()
```

The cleaned penguins dataset has `{python} len(penguins_cleaned_df)` rows.

# Clustering

```{python}
# | label: set-model-parameters
selected_features = ["bill_length_mm", "flipper_length_mm"]

model_params = {"n_clusters": 3,
                "max_iter": 300}

penguins_data_df = penguins_cleaned_df.copy()

features_df = penguins_data_df.loc[:, selected_features]

cols_compare = ["species",
                "cluster", "bill_length_mm", "flipper_length_mm"]
```

Our model has these parameters:

- Number of Clusters: `{python} model_params["n_clusters"]`

- Max Iterations: `{python} model_params["max_iter"]`

```{python}
# | label: scale-features
standard_scalar = StandardScaler()
features_standard_scalar = standard_scalar.fit_transform(features_df)
```

```{python}
# | label: kmean-clustering
kmeans_model = KMeans(
    n_clusters=model_params["n_clusters"], max_iter=model_params["max_iter"])

penguin_predictions = kmeans_model.fit_predict(features_standard_scalar)
penguins_data_df.loc[:, "cluster"] = penguin_predictions
```

# Model performance

```{python}
# | label: label-cluster-by-largest-cound
cluster_species_df = penguins_data_df.groupby(
    "species")["cluster"].agg(lambda x: x.value_counts().index[1]).reset_index()

# Insert cluster ids into data and then replace with the
# species label for pretty displaying
penguins_data_df['cluster'] = penguins_data_df['cluster'].astype(str)
cluster_species_df['cluster'] = cluster_species_df['cluster'].astype(str)
```

```{python}
# | label: augment-data-with-clusters
penguins_data_df.loc[:, "cluster"] = penguins_data_df["cluster"].map(
    cluster_species_df.set_index("cluster")["species"])

penguins_selected_df = penguins_data_df[cols_compare]

penguins_selected_df = penguins_selected_df.rename(columns={
    "species": "actual_species", "cluster": "predicted_species"})
```

```{python}
# | label: confusion_matrix
penguins_confusion = pd.crosstab(penguins_selected_df['predicted_species'],
                                 penguins_selected_df['actual_species'])

penguins_confusion_mismatch = penguins_confusion.copy()

np.fill_diagonal(penguins_confusion_mismatch.values, 0)

```

Out of `{python} penguins_confusion.sum().sum().item()` penguins, our model misclassified `{python} round(penguins_confusion_mismatch.sum().sum().item() / penguins_confusion.sum().sum().item(), 2) * 100`% of the penguins.

```{python}
# | echo: true
import plotnine as pn
penguins_clust_long = pd.melt(penguins_selected_df,
                              id_vars=["bill_length_mm", "flipper_length_mm"],
                              var_name="measure",
                              value_name="group")
(
    pn.ggplot(penguins_clust_long, pn.aes("bill_length_mm",
                                          "flipper_length_mm", color="factor(group)"))
    + pn.geom_point()
    + pn.facet_wrap("measure")
)
```
